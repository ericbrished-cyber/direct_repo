{
  "stats": {
    "total": 10,
    "success": 10,
    "failed": 0,
    "skipped": 0
  },
  "failures": [],
  "eval": {
    "run_name": "gpt_5_1_fewshot_20251209_103018",
    "num_articles": 10,
    "total_gold_fields": 182,
    "total_pred_fields": 194,
    "total_tp": 106,
    "total_fp": 18,
    "total_fn": 76,
    "total_tn": 144,
    "macro_precision": 0.735,
    "macro_recall": 0.66875,
    "macro_f1": 0.6713498124375071,
    "micro_precision": 0.8548387096774194,
    "micro_recall": 0.5824175824175825,
    "micro_f1": 0.6928104575163399,
    "overall_mse": 918.7589488636366,
    "overall_rmse": 30.311036750062453,
    "total_mse_comparisons": 176,
    "exact_match_accuracy": 0.2903225806451613,
    "exact_match_correct": 9,
    "exact_match_total": 31,
    "exact_match_by_type": {
      "binary": {
        "correct": 6,
        "total": 8,
        "accuracy": 0.75
      },
      "continuous": {
        "correct": 3,
        "total": 23,
        "accuracy": 0.13043478260869565
      }
    },
    "per_field_micro": {
      "intervention_group_size": {
        "tp": 24,
        "fp": 0,
        "fn": 17,
        "tn": 2,
        "precision": 1.0,
        "recall": 0.5853658536585366,
        "f1": 0.7384615384615384,
        "mse": 11.875,
        "rmse": 3.4460121880225554,
        "num_comparisons": 40
      },
      "comparator_group_size": {
        "tp": 24,
        "fp": 0,
        "fn": 17,
        "tn": 2,
        "precision": 1.0,
        "recall": 0.5853658536585366,
        "f1": 0.7384615384615384,
        "mse": 7.6,
        "rmse": 2.756809750418044,
        "num_comparisons": 40
      },
      "intervention_events": {
        "tp": 6,
        "fp": 3,
        "fn": 2,
        "tn": 32,
        "precision": 0.6666666666666666,
        "recall": 0.75,
        "f1": 0.7058823529411765,
        "mse": 0.0,
        "rmse": 0.0,
        "num_comparisons": 6
      },
      "comparator_events": {
        "tp": 6,
        "fp": 3,
        "fn": 2,
        "tn": 32,
        "precision": 0.6666666666666666,
        "recall": 0.75,
        "f1": 0.7058823529411765,
        "mse": 0.0,
        "rmse": 0.0,
        "num_comparisons": 6
      },
      "intervention_mean": {
        "tp": 12,
        "fp": 5,
        "fn": 11,
        "tn": 15,
        "precision": 0.7058823529411765,
        "recall": 0.5217391304347826,
        "f1": 0.6,
        "mse": 5847.703508695653,
        "rmse": 76.47027859695329,
        "num_comparisons": 23
      },
      "comparator_mean": {
        "tp": 15,
        "fp": 5,
        "fn": 8,
        "tn": 15,
        "precision": 0.75,
        "recall": 0.6521739130434783,
        "f1": 0.6976744186046512,
        "mse": 13.58325652173914,
        "rmse": 3.685546977280189,
        "num_comparisons": 23
      },
      "intervention_standard_deviation": {
        "tp": 9,
        "fp": 1,
        "fn": 10,
        "tn": 23,
        "precision": 0.9,
        "recall": 0.47368421052631576,
        "f1": 0.6206896551724138,
        "mse": 1354.102321052632,
        "rmse": 36.79812931458109,
        "num_comparisons": 19
      },
      "comparator_standard_deviation": {
        "tp": 10,
        "fp": 1,
        "fn": 9,
        "tn": 23,
        "precision": 0.9090909090909091,
        "recall": 0.5263157894736842,
        "f1": 0.6666666666666666,
        "mse": 20.26501578947368,
        "rmse": 4.501668111875161,
        "num_comparisons": 19
      }
    }
  },
  "run_folder": "outputs/gpt_5_1_fewshot_20251209_103018"
}